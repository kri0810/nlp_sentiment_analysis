{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QEDyiExAVqLA"
      },
      "outputs": [],
      "source": [
        "#importing necessary libraries\n",
        "import pandas as pd\n",
        "import string\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWBHYXLQHkAv",
        "outputId": "2b08784a-ea70-4f30-f946-d625da55c5a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyluCz9q6xYk",
        "outputId": "e8bc55e5-8347-43dd-c388-58733389ba4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "RcFx2KLEVfXs",
        "outputId": "cb49097e-ae4b-4c5f-a4a8-f663386bcfac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id                                              tweet subtask_a  \\\n",
              "0      86426  @USER She should ask a few native Americans wh...       OFF   \n",
              "1      90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
              "2      16820  Amazon is investigating Chinese employees who ...       NOT   \n",
              "3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
              "4      43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
              "...      ...                                                ...       ...   \n",
              "13188  94475  @USER every antifa member is just several midg...       NOT   \n",
              "13189  34150    @USER Berkeley Antifa do not agree with you URL       NOT   \n",
              "13190  83400        @USER You are a great model for inspiration       NOT   \n",
              "13191  84081  @USER Chris, Chris, Chris.... Are you forgetti...       OFF   \n",
              "13192  11244  @USER Advocate for gun control while breaking ...       NOT   \n",
              "\n",
              "      subtask_b subtask_c  \n",
              "0           UNT       NaN  \n",
              "1           TIN       IND  \n",
              "2           NaN       NaN  \n",
              "3           UNT       NaN  \n",
              "4           NaN       NaN  \n",
              "...         ...       ...  \n",
              "13188       NaN       NaN  \n",
              "13189       NaN       NaN  \n",
              "13190       NaN       NaN  \n",
              "13191       UNT       NaN  \n",
              "13192       NaN       NaN  \n",
              "\n",
              "[13193 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf85dc08-9596-45d7-a9c4-5537bf682278\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13188</th>\n",
              "      <td>94475</td>\n",
              "      <td>@USER every antifa member is just several midg...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13189</th>\n",
              "      <td>34150</td>\n",
              "      <td>@USER Berkeley Antifa do not agree with you URL</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13190</th>\n",
              "      <td>83400</td>\n",
              "      <td>@USER You are a great model for inspiration</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13191</th>\n",
              "      <td>84081</td>\n",
              "      <td>@USER Chris, Chris, Chris.... Are you forgetti...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13192</th>\n",
              "      <td>11244</td>\n",
              "      <td>@USER Advocate for gun control while breaking ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13193 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf85dc08-9596-45d7-a9c4-5537bf682278')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf85dc08-9596-45d7-a9c4-5537bf682278 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf85dc08-9596-45d7-a9c4-5537bf682278');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2acd2015-6809-411c-bf9b-676a3956e6b1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2acd2015-6809-411c-bf9b-676a3956e6b1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2acd2015-6809-411c-bf9b-676a3956e6b1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 13193,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26087,\n        \"min\": 10006,\n        \"max\": 99986,\n        \"samples\": [\n          29648,\n          65662,\n          38990\n        ],\n        \"num_unique_values\": 13193,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"@USER @USER @USER I\\u2019m not \\u2018from antifa\\u2019 I will just be happy when Sam dies\",\n          \"@USER My fault was never with news crews reporting from within disaster areas; it was only with live shots in dangerous situations. I think it's detrimental, because a viewer could see that and say, If he or she is out in that weather, it can't be that bad.\\\"\\\"\",\n          \"@USER What manga you reading?\"\n        ],\n        \"num_unique_values\": 13160,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subtask_a\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"NOT\",\n          \"OFF\"\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subtask_b\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"TIN\",\n          \"UNT\"\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subtask_c\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"IND\",\n          \"OTH\"\n        ],\n        \"num_unique_values\": 3,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#loading the dataset after converting tsv into csv\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/olid-training.csv\")\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "-wuj8KVKJEpq",
        "outputId": "e5c286a2-7da5-455e-965e-16f718cc3677"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'from sklearn.utils import resample\\nimport pandas as pd\\n\\n# Separate the majority and minority classes\\nmajority_class = train_data[train_data[\\'subtask_a\\'] == \\'NOT\\']\\nminority_class = train_data[train_data[\\'subtask_a\\'] == \\'OFF\\']\\n\\n# Checking counts of majority and minority classes\\nprint(\"Original Counts - Majority:\", len(majority_class), \"Minority:\", len(minority_class))\\n\\n# Oversample the minority class to match the number of majority class instances\\noversampled_minority = resample(minority_class,\\n                                replace=True,  # Sample with replacement\\n                                n_samples=len(majority_class),  # Match number of majority class instances\\n                                random_state=42)  # Reproducible results\\n\\n# Combine oversampled minority class with majority class\\nbalanced_data = pd.concat([majority_class, oversampled_minority])\\n\\n\\nprint(\"Balanced Data Shape:\", balanced_data.shape)'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''from sklearn.utils import resample\n",
        "import pandas as pd\n",
        "\n",
        "# Separate the majority and minority classes\n",
        "majority_class = train_data[train_data['subtask_a'] == 'NOT']\n",
        "minority_class = train_data[train_data['subtask_a'] == 'OFF']\n",
        "\n",
        "# Checking counts of majority and minority classes\n",
        "print(\"Original Counts - Majority:\", len(majority_class), \"Minority:\", len(minority_class))\n",
        "\n",
        "# Oversample the minority class to match the number of majority class instances\n",
        "oversampled_minority = resample(minority_class,\n",
        "                                replace=True,  # Sample with replacement\n",
        "                                n_samples=len(majority_class),  # Match number of majority class instances\n",
        "                                random_state=42)  # Reproducible results\n",
        "\n",
        "# Combine oversampled minority class with majority class\n",
        "balanced_data = pd.concat([majority_class, oversampled_minority])\n",
        "\n",
        "\n",
        "print(\"Balanced Data Shape:\", balanced_data.shape)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm9GieXLCneL",
        "outputId": "f37d7d10-720d-46db-c209-11fad3e343a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   tweet\n",
            "0      @USER She should ask a few native Americans wh...\n",
            "1      @USER @USER Go home you’re drunk!!! @USER #MAG...\n",
            "2      Amazon is investigating Chinese employees who ...\n",
            "3      @USER Someone should'veTaken\" this piece of sh...\n",
            "4      @USER @USER Obama wanted liberals &amp; illega...\n",
            "...                                                  ...\n",
            "13188  @USER every antifa member is just several midg...\n",
            "13189    @USER Berkeley Antifa do not agree with you URL\n",
            "13190        @USER You are a great model for inspiration\n",
            "13191  @USER Chris, Chris, Chris.... Are you forgetti...\n",
            "13192  @USER Advocate for gun control while breaking ...\n",
            "\n",
            "[13193 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "#displaying the tweets\n",
        "train_tweets = train_data[[\"tweet\"]]\n",
        "print(train_tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-qMUz75HUvu",
        "outputId": "66fd66fe-8510-42d2-8d26-64fef8f0b2b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        " #checking for duplicate tweets\n",
        " train_data[\"tweet\"].duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcZ6Lh-vJG_a",
        "outputId": "b64d429b-6dc4-4816-d829-3728bfd56499"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "subtask_a\n",
              "NOT          8804\n",
              "OFF          4389\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "#value counts of subtask a after balancing\n",
        "train_data[['subtask_a']].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z8e8QI5V7gt",
        "outputId": "ee26beb2-4899-40f4-8fa4-deb51368f9c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          id                                              tweet subtask_a  \\\n",
            "0      86426  @USER She should ask a few native Americans wh...       OFF   \n",
            "1      90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
            "2      16820  Amazon is investigating Chinese employees who ...       NOT   \n",
            "3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
            "4      43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
            "...      ...                                                ...       ...   \n",
            "13188  94475  @USER every antifa member is just several midg...       NOT   \n",
            "13189  34150    @USER Berkeley Antifa do not agree with you URL       NOT   \n",
            "13190  83400        @USER You are a great model for inspiration       NOT   \n",
            "13191  84081  @USER Chris, Chris, Chris.... Are you forgetti...       OFF   \n",
            "13192  11244  @USER Advocate for gun control while breaking ...       NOT   \n",
            "\n",
            "      subtask_b subtask_c  \n",
            "0           UNT       NaN  \n",
            "1           TIN       IND  \n",
            "2           NaN       NaN  \n",
            "3           UNT       NaN  \n",
            "4           NaN       NaN  \n",
            "...         ...       ...  \n",
            "13188       NaN       NaN  \n",
            "13189       NaN       NaN  \n",
            "13190       NaN       NaN  \n",
            "13191       UNT       NaN  \n",
            "13192       NaN       NaN  \n",
            "\n",
            "[13193 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "train_task_a_labels= train_data[['subtask_a']] #Extract subtsak_a labels\n",
        "train_task_b_labels= train_data[['subtask_b']] #Extract subtsak_b labels\n",
        "train_task_c_labels= train_data[['subtask_c']] #Extract subtsak_c labels\n",
        "\n",
        "train_task_a_labels.columns.values[0] = 'class_a' #Rename class attribute\n",
        "train_task_b_labels.columns.values[0] = 'class_b' #Rename class attribute\n",
        "train_task_c_labels.columns.values[0] = 'class_c' #Rename class attribute\n",
        "\n",
        "print(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1bAuiH5SacZC"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def clean_tweets(df):\n",
        "    punctuations = string.punctuation\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Remove mentions, URLs, and special characters\n",
        "    df.loc[:, 'tweet'] = df.tweet.str.replace('@USER', '') \\\n",
        "                                    .str.replace('URL', '') \\\n",
        "                                    .str.replace('&amp', 'and') \\\n",
        "                                    .str.replace('&lt','') \\\n",
        "                                    .str.replace('&gt','') \\\n",
        "                                    .str.replace('\\d+','') \\\n",
        "                                    .str.lower()\n",
        "\n",
        "    # Remove punctuations\n",
        "    for punctuation in punctuations:\n",
        "        df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
        "\n",
        "    # Remove emojis\n",
        "    df.loc[:, 'tweet'] = df.tweet.apply(lambda x: re.sub(r'[^\\x00-\\x7F]+', '', x))\n",
        "\n",
        "    # Remove stopwords\n",
        "    df.loc[:, 'tweet'] = df.tweet.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "\n",
        "    # Trim leading and trailing whitespaces\n",
        "    df.loc[:, 'tweet'] = df.tweet.str.strip()\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUSlrFGn0vPx",
        "outputId": "0e8ec5a5-4060-49fc-e5de-0f716d1ea113"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-tgyiB5rW3qL",
        "outputId": "db2ed12b-e543-4ba9-be7d-a9b7ab6a2531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-0e83b4979b94>:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  .str.replace('\\d+','') \\\n",
            "<ipython-input-9-0e83b4979b94>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace('@USER', '') \\\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-9-0e83b4979b94>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.apply(lambda x: re.sub(r'[^\\x00-\\x7F]+', '', x))\n",
            "<ipython-input-9-0e83b4979b94>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
            "<ipython-input-9-0e83b4979b94>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.strip()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   tweet\n",
              "0                              ask native americans take\n",
              "1                         go home youre drunk maga trump\n",
              "2      amazon investigating chinese employees selling...\n",
              "3               someone shouldvetaken piece shit volcano\n",
              "4         obama wanted liberals illegals move red states\n",
              "...                                                  ...\n",
              "13188  every antifa member several midget gypsies sta...\n",
              "13189                              berkeley antifa agree\n",
              "13190                            great model inspiration\n",
              "13191  chris chris chris forgetting mantra every sing...\n",
              "13192  advocate gun control breaking current gun laws...\n",
              "\n",
              "[13193 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b288583-1efb-4759-bd34-82f0f5653b28\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ask native americans take</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>go home youre drunk maga trump</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amazon investigating chinese employees selling...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>someone shouldvetaken piece shit volcano</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>obama wanted liberals illegals move red states</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13188</th>\n",
              "      <td>every antifa member several midget gypsies sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13189</th>\n",
              "      <td>berkeley antifa agree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13190</th>\n",
              "      <td>great model inspiration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13191</th>\n",
              "      <td>chris chris chris forgetting mantra every sing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13192</th>\n",
              "      <td>advocate gun control breaking current gun laws...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13193 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b288583-1efb-4759-bd34-82f0f5653b28')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9b288583-1efb-4759-bd34-82f0f5653b28 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9b288583-1efb-4759-bd34-82f0f5653b28');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a0959b9a-158d-4cf4-8e13-e13e6d522555\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a0959b9a-158d-4cf4-8e13-e13e6d522555')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a0959b9a-158d-4cf4-8e13-e13e6d522555 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_tweets",
              "summary": "{\n  \"name\": \"train_tweets\",\n  \"rows\": 13193,\n  \"fields\": [\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"looks like perfect illustration gun control letsgoshooting\",\n          \"love wit clearly perceptive smart one best play game played hard like andy said\",\n          \"need marijuana lobby bribe gop like big pharma otherwise youre screwed good america means nothing see gun control\"\n        ],\n        \"num_unique_values\": 12808,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "clean_tweets(train_tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "t-iF5dt2W68i"
      },
      "outputs": [],
      "source": [
        "train_task_a_data = train_tweets.join(train_task_a_labels)\n",
        "\n",
        "train_task_b_data = train_tweets.join(train_task_b_labels)\n",
        "train_task_b_data = train_task_b_data.dropna() #Drop records with missing values\n",
        "\n",
        "train_task_c_data = train_tweets.join(train_task_c_labels)\n",
        "train_task_c_data = train_task_c_data.dropna() #Drop records with missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9NGkzKjdyjk",
        "outputId": "427ddf22-f501-46ca-968e-707b9867fe2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet 1: ['ask', 'native', 'americans', 'take']\n",
            "Tweet 2: ['go', 'home', 'youre', 'drunk', 'maga', 'trump']\n",
            "Tweet 3: ['amazon', 'investigating', 'chinese', 'employees', 'selling', 'internal', 'data', 'thirdparty', 'sellers', 'looking', 'edge', 'competitive', 'marketplace', 'amazon', 'maga', 'kag', 'china', 'tcot']\n",
            "Tweet 4: ['someone', 'shouldvetaken', 'piece', 'shit', 'volcano']\n",
            "Tweet 5: ['obama', 'wanted', 'liberals', 'illegals', 'move', 'red', 'states']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def tokenize_tweets(tweets):\n",
        "\n",
        "    tokenized_tweets = [word_tokenize(tweet) for tweet in tweets]\n",
        "    return tokenized_tweets\n",
        "\n",
        "\n",
        "#  train_tweets['tweet'] contains the list of tweets\n",
        "tweets = train_tweets['tweet']\n",
        "tokenized_tweets = tokenize_tweets(tweets)\n",
        "\n",
        "# Printing the first few tokenized tweets for verification\n",
        "for i in range(5):  # Print the first 5 tokenized tweets\n",
        "    print(f\"Tweet {i + 1}: {tokenized_tweets[i]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6iqLAtmwy3C",
        "outputId": "affddc12-4c6f-4d58-8551-a51ecb73cce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Tweet 1: ['ask', 'native', 'american', 'take']\n",
            "Lemmatized Tweet 2: ['go', 'home', 'youre', 'drunk', 'maga', 'trump']\n",
            "Lemmatized Tweet 3: ['amazon', 'investigating', 'chinese', 'employee', 'selling', 'internal', 'data', 'thirdparty', 'seller', 'looking', 'edge', 'competitive', 'marketplace', 'amazon', 'maga', 'kag', 'china', 'tcot']\n",
            "Lemmatized Tweet 4: ['someone', 'shouldvetaken', 'piece', 'shit', 'volcano']\n",
            "Lemmatized Tweet 5: ['obama', 'wanted', 'liberal', 'illegals', 'move', 'red', 'state']\n",
            "13193\n"
          ]
        }
      ],
      "source": [
        "#Lemmatization preserves the semantic meaning of words better than stemming and is less likely to introduce non-standard words.\n",
        "# lemmatization also considers different POS tags\n",
        "#lemm using nltk\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def lemmatize_tweets(tokenized_tweets):\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tweets = []\n",
        "    for tweet_tokens in tokenized_tweets:\n",
        "        lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tweet_tokens]\n",
        "        lemmatized_tweets.append(lemmatized_tokens)\n",
        "    return lemmatized_tweets\n",
        "\n",
        "# Assuming tokenized_tweets contains the list of tokenized tweets\n",
        "lemmatized_tweets = lemmatize_tweets(tokenized_tweets)\n",
        "\n",
        "# Printing the first few lemmatized tweets for verification\n",
        "for i in range(5):  # Print the first 5 lemmatized tweets\n",
        "    print(f\"Lemmatized Tweet {i + 1}: {lemmatized_tweets[i]}\")\n",
        "print(len(lemmatized_tweets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j42KF1neOZP4",
        "outputId": "df208b3f-e7e7-4aa1-d0ac-4a2a64fb7a26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                ask native americans take\n",
              "1                           go home youre drunk maga trump\n",
              "2        amazon investigating chinese employees selling...\n",
              "3                 someone shouldvetaken piece shit volcano\n",
              "4           obama wanted liberals illegals move red states\n",
              "                               ...                        \n",
              "13188    every antifa member several midget gypsies sta...\n",
              "13189                                berkeley antifa agree\n",
              "13190                              great model inspiration\n",
              "13191    chris chris chris forgetting mantra every sing...\n",
              "13192    advocate gun control breaking current gun laws...\n",
              "Name: tweet, Length: 13193, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train_tweets[\"tweet\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "NLEcKftQMPas",
        "outputId": "142bc202-1e1a-4624-cd89-102777eab208"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"#word cloud after pre-processing\\nfrom nltk.stem import WordNetLemmatizer\\nfrom wordcloud import WordCloud\\nimport matplotlib.pyplot as plt\\n\\n# Sample lemmatized_tweets data (replace it with your actual lemmatized tweets)\\nlemmatized_tweets =[ train_tweets['tweet']]\\n\\n# Initialize the WordNetLemmatizer\\nlemmatizer = WordNetLemmatizer()\\n\\n# Combine all lemmatized tokens into a single text corpus\\ntext_corpus = ' '.join([' '.join([lemmatizer.lemmatize(token) for token in tweet_tokens]) for tweet_tokens in lemmatized_tweets])\\n\\n# Generate the word cloud\\nwordcloud = WordCloud(width=800, height=400, background_color='white').generate(text_corpus)\\n\\n# Display the word cloud using matplotlib\\nplt.figure(figsize=(10, 6))\\nplt.imshow(wordcloud, interpolation='bilinear')\\nplt.axis('off')\\nplt.show()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "'''#word cloud after pre-processing\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample lemmatized_tweets data (replace it with your actual lemmatized tweets)\n",
        "lemmatized_tweets =[ train_tweets['tweet']]\n",
        "\n",
        "# Initialize the WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Combine all lemmatized tokens into a single text corpus\n",
        "text_corpus = ' '.join([' '.join([lemmatizer.lemmatize(token) for token in tweet_tokens]) for tweet_tokens in lemmatized_tweets])\n",
        "\n",
        "# Generate the word cloud\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text_corpus)\n",
        "\n",
        "# Display the word cloud using matplotlib\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mQTD7isep2E",
        "outputId": "7e737209-49f7-4efd-b787-835d5205ac1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Matrix:\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "Feature Names:\n",
            "['aaron' 'ab' 'abiding' ... 'zero evidence' 'zombie' 'zone']\n",
            "(13193, 5000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def tfidf_vectorize_tweets(tweets, max_features=5000, ngram_range=(1, 3), stop_words='english'):\n",
        "\n",
        "    # Initialize the TfidfVectorizer with desired parameters\n",
        "    tfidf_vectorizer = TfidfVectorizer(max_features=max_features, stop_words=stop_words, ngram_range=ngram_range)\n",
        "\n",
        "    # Fit the vectorizer to the tweets and transform them into TF-IDF vectors\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(tweets)\n",
        "\n",
        "    # Get the feature names (words) from the vectorizer\n",
        "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "    return tfidf_matrix, feature_names\n",
        "\n",
        "# Example usage:\n",
        "# Assuming lemmatized_tweet_strings contains the list of lemmatized tweet strings\n",
        "lemmatized_tweet_strings = [' '.join(tokens) for tokens in lemmatized_tweets]\n",
        "tfidf_matrix, feature_names = tfidf_vectorize_tweets(lemmatized_tweet_strings)\n",
        "\n",
        "# Print the TF-IDF matrix and feature names\n",
        "print(\"TF-IDF Matrix:\")\n",
        "print(tfidf_matrix.toarray())\n",
        "print(\"\\nFeature Names:\")\n",
        "print(feature_names)\n",
        "print(tfidf_matrix.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "-BvAM4ub3Tkn",
        "outputId": "b30f1156-92c7-4226-b433-a01c824f4558"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'vectorization using tfidf\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\n\\n# Convert the lemmatized tweets back to strings\\nlemmatized_tweet_strings = [\\' \\'.join(tokens) for tokens in lemmatized_tweets]\\n\\n# Initializing the TfidfVectorizer with desired parameters\\ntfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=\\'english\\', ngram_range=(1, 3))\\n\\n# Fit the vectorizer to the lemmatized tweets and transform them into TF-IDF vectors\\ntfidf_matrix = tfidf_vectorizer.fit_transform(lemmatized_tweet_strings)\\n\\n# Get the feature names (words) from the vectorizer\\nfeature_names = tfidf_vectorizer.get_feature_names_out()\\n\\n# Print the TF-IDF matrix and feature names\\nprint(\"TF-IDF Matrix:\")\\nprint(tfidf_matrix.toarray())\\nprint(\"\\nFeature Names:\")\\nprint(feature_names)\\n\\nprint(tfidf_matrix.shape)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "'''vectorization using tfidf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Convert the lemmatized tweets back to strings\n",
        "lemmatized_tweet_strings = [' '.join(tokens) for tokens in lemmatized_tweets]\n",
        "\n",
        "# Initializing the TfidfVectorizer with desired parameters\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 3))\n",
        "\n",
        "# Fit the vectorizer to the lemmatized tweets and transform them into TF-IDF vectors\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(lemmatized_tweet_strings)\n",
        "\n",
        "# Get the feature names (words) from the vectorizer\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Print the TF-IDF matrix and feature names\n",
        "print(\"TF-IDF Matrix:\")\n",
        "print(tfidf_matrix.toarray())\n",
        "print(\"\\nFeature Names:\")\n",
        "print(feature_names)\n",
        "\n",
        "print(tfidf_matrix.shape)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4VMpvWCMBYK",
        "outputId": "528790af-b006-4048-bb91-3a9e64d6e721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17608,)\n"
          ]
        }
      ],
      "source": [
        "#overrsampling using Resample library\n",
        "combined_data = pd.concat([pd.DataFrame(tfidf_matrix.toarray()), train_data['subtask_a']], axis=1)\n",
        "\n",
        "# Separate majority and minority classes\n",
        "majority_class = combined_data[combined_data['subtask_a'] == 'NOT']\n",
        "minority_class = combined_data[combined_data['subtask_a'] == 'OFF']\n",
        "\n",
        "# Upsample minority class\n",
        "minority_upsampled = resample(minority_class,\n",
        "                               replace=True,  # Sample with replacement\n",
        "                               n_samples=len(majority_class),  # Match number in majority class\n",
        "                               random_state=42)  # Reproducible results\n",
        "\n",
        "# Combine majority class with upsampled minority class\n",
        "upsampled_data = pd.concat([minority_upsampled, majority_class])\n",
        "\n",
        "# Separate features (TF-IDF matrix) and labels\n",
        "X_upsampled = upsampled_data.drop('subtask_a', axis=1)\n",
        "y_upsampled = upsampled_data['subtask_a']\n",
        "print(upsampled_data['subtask_a'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvlEqIpFnk78",
        "outputId": "ea1ae8cf-cfc5-49f8-ebf1-06e702cfeeb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.2-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.2\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-2.10.2-py3-none-any.whl (19.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Collecting gitpython<4,>=2.1.0 (from mlflow)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pytz<2024 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.4)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: packaging<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.2)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.0.1)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4.4)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.25.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.3)\n",
            "Collecting querystring-parser<2 (from mlflow)\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.27)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: pyarrow<16,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (10.0.1)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.5.2)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Collecting gunicorn<22 (from mlflow)\n",
            "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.3)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.0.7)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.1.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from querystring-parser<2->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.2.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, querystring-parser, Mako, gunicorn, gitdb, docker, alembic, gitpython, mlflow\n",
            "Successfully installed Mako-1.3.2 alembic-1.13.1 docker-7.0.0 gitdb-4.0.11 gitpython-3.1.42 gunicorn-21.2.0 mlflow-2.10.2 querystring-parser-1.2.4 smmap-5.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n",
        "!pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "fwFFUdNJngSF"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "\n",
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2gzgqzHT1bx",
        "outputId": "66f310c7-1047-430e-844e-3d0ea5f9297f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow Tracking UI: https://b556-34-139-124-11.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "ngrok.set_auth_token(\"2cOmU3gU4HCbJ0fV5y4Fu3Hmyjg_2x7nShWq2kSEf1PteU8an\")\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xFJabsfjtCd4"
      },
      "outputs": [],
      "source": [
        "mlflow.set_tracking_uri(\"/content/drive/MyDrive/mlf\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "LlCyOcj6WIJ2"
      },
      "outputs": [],
      "source": [
        "run = mlflow.active_run()\n",
        "if run:\n",
        "    print(\"Active run_id: {}\".format(run.info.run_id))\n",
        "    mlflow.end_run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHXMpihdPGrs",
        "outputId": "714680e2-8304-4323-ca89-6adac6316ad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7893242475865985\n"
          ]
        }
      ],
      "source": [
        "mlflow.set_experiment('TNF_EXP')\n",
        "experiment = mlflow.get_experiment_by_name(\"TNF_EXP\")\n",
        "with mlflow.start_run(experiment_id=experiment.experiment_id) as run:\n",
        "    # Add parameters\n",
        "    mlflow.log_param(\"C\", 1)\n",
        "    mlflow.log_param(\"penalty\", 'l2')\n",
        "    mlflow.log_param(\"random_state\", 42)\n",
        "#Split the upsampled data into training and testing sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the logistic regression model\n",
        "logistic_model = LogisticRegression(C = 1, penalty = 'l2',random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict labels for the testing data\n",
        "lr_pred = logistic_model.predict(X_val)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, lr_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lgBJZbIWjFu",
        "outputId": "d4d038b4-b4a3-433f-b1a7-c1d109a59fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-02-16 12:01:20 +0000] [1906] [INFO] Starting gunicorn 21.2.0\n",
            "[2024-02-16 12:01:20 +0000] [1906] [INFO] Listening at: http://0.0.0.0:5000 (1906)\n",
            "[2024-02-16 12:01:20 +0000] [1906] [INFO] Using worker: sync\n",
            "[2024-02-16 12:01:20 +0000] [1907] [INFO] Booting worker with pid: 1907\n",
            "[2024-02-16 12:01:20 +0000] [1908] [INFO] Booting worker with pid: 1908\n",
            "[2024-02-16 12:01:20 +0000] [1909] [INFO] Booting worker with pid: 1909\n",
            "[2024-02-16 12:01:21 +0000] [1910] [INFO] Booting worker with pid: 1910\n",
            "[2024-02-16 12:02:55 +0000] [1906] [INFO] Handling signal: int\n",
            "[2024-02-16 12:02:55 +0000] [1909] [INFO] Worker exiting (pid: 1909)\n",
            "[2024-02-16 12:02:55 +0000] [1908] [INFO] Worker exiting (pid: 1908)\n",
            "[2024-02-16 12:02:55 +0000] [1907] [INFO] Worker exiting (pid: 1907)\n",
            "[2024-02-16 12:02:55 +0000] [1910] [INFO] Worker exiting (pid: 1910)\n",
            "\n",
            "Aborted!\n",
            "[2024-02-16 12:02:56 +0000] [1906] [INFO] Shutting down: Master\n"
          ]
        }
      ],
      "source": [
        "!mlflow ui --port 5000 --host 0.0.0.0 --backend-store-uri file:///\"/content/drive/MyDrive/mlf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "veA6mbdO4YRg",
        "outputId": "8580ae41-a332-4a45-d685-1e50fe599ac7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Apply SMOTE to oversample the majority class\\nsmote = SMOTE(sampling_strategy=\\'minority\\', random_state=42)\\nX_resampled, y_resampled = smote.fit_resample(tfidf_matrix, train_data[\\'subtask_a\\'])\\n\\n# Split the resampled TF-IDF matrix and labels into train and validation sets\\nX_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\\n\\n# Initialize and fit the logistic regression model\\nlogistic_model = LogisticRegression(max_iter=1000)  # Increase max_iter if needed\\nlogistic_model.fit(X_train, y_train)\\n\\n# Predicting labels for the validation set\\ny_pred_val = logistic_model.predict(X_val)\\n\\n# Calculate accuracy score for validation set\\naccuracy_val = accuracy_score(y_val, y_pred_val)\\nprint(\"Validation Accuracy:\", accuracy_val)\\n\\n# Predicting labels for the training set\\ny_pred_train = logistic_model.predict(X_train)\\n\\n# Calculate accuracy score for training set\\naccuracy_train = accuracy_score(y_train, y_pred_train)\\nprint(\"Training Accuracy:\", accuracy_train)'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "'''\n",
        "# Apply SMOTE to oversample the majority class\n",
        "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(tfidf_matrix, train_data['subtask_a'])\n",
        "\n",
        "# Split the resampled TF-IDF matrix and labels into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and fit the logistic regression model\n",
        "logistic_model = LogisticRegression(max_iter=1000)  # Increase max_iter if needed\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting labels for the validation set\n",
        "y_pred_val = logistic_model.predict(X_val)\n",
        "\n",
        "# Calculate accuracy score for validation set\n",
        "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
        "print(\"Validation Accuracy:\", accuracy_val)\n",
        "\n",
        "# Predicting labels for the training set\n",
        "y_pred_train = logistic_model.predict(X_train)\n",
        "\n",
        "# Calculate accuracy score for training set\n",
        "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
        "print(\"Training Accuracy:\", accuracy_train)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMgtfQeLBW2l",
        "outputId": "3cb408d0-8adf-4e37-f8f3-21166e187ce6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training Accuracy: 0.7491474043198181\n",
            "testing Accuracy: 0.8082243699071442\n"
          ]
        }
      ],
      "source": [
        "#lr model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have labels associated with your lemmatized tweets\n",
        "# Replace 'labels' with the actual labels from your dataset\n",
        "\n",
        "# Split the TF-IDF matrix and labels into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(tfidf_matrix, train_data['subtask_a'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and fit the logistic regression model\n",
        "logistic_model = LogisticRegression(max_iter=1000)  # Increase max_iter if needed\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting labels for the validation set\n",
        "lr_pred = logistic_model.predict(X_val)\n",
        "\n",
        "# accuracy score for validation set\n",
        "accuracy = accuracy_score(y_val, lr_pred)\n",
        "print(\"training Accuracy:\", accuracy)\n",
        "\n",
        "# Predicting labels for the training set\n",
        "y_pred_tr = logistic_model.predict(X_train)\n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy = accuracy_score(y_train, y_pred_tr)\n",
        "print(\"testing Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7JNFS8yDtNZ",
        "outputId": "a95c6aa7-7e1d-48f0-d54c-371e0b9e5b5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_Accuracy: 0.8770584894946053\n",
            "train_Accuracy: 0.989422121255147\n"
          ]
        }
      ],
      "source": [
        "#rf model\n",
        "\n",
        "\n",
        "# Split the TF-IDF matrix and labels into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and fit the Random Forest classifier\n",
        "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict labels for the validation set\n",
        "rf_pred = random_forest_model.predict(X_val)\n",
        "\n",
        "# Calculated accuracy score\n",
        "accuracy = accuracy_score(y_val, rf_pred)\n",
        "print(\"val_Accuracy:\", accuracy)\n",
        "\n",
        "# Predict labels for the training set\n",
        "y_pred_train = random_forest_model.predict(X_train)\n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
        "print(\"train_Accuracy:\", accuracy_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_colVur7Hby",
        "outputId": "ef99566a-df55-4bf5-8fcf-71edc8bac16c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6503416856492027\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# Initialize and fit the Random Forest classifier\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "dt_pred = dt_model.predict(X_val)\n",
        "acc = accuracy_score(y_val, dt_pred)\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngVogKSgALHl"
      },
      "outputs": [],
      "source": [
        "# Convert predictions to binary (0 or 1) if they are not already\n",
        "rf_pred = random_forest_model.predict_proba(X_val)[:, 1]  # Assuming you want the probability of the positive class\n",
        "lr_pred = logistic_model.predict_proba(X_val)[:, 1]\n",
        "dt_pred = dt_model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Convert probabilities to binary predictions using a threshold of 0.5\n",
        "rf_pred_binary = (rf_pred >= 0.5).astype(int)\n",
        "lr_pred_binary = (lr_pred >= 0.5).astype(int)\n",
        "dt_pred_binary = (dt_pred >= 0.5).astype(int)\n",
        "\n",
        "# Combine predictions using simple majority voting\n",
        "ensemble_predictions = (rf_pred_binary + lr_pred_binary + dt_pred_binary) >= 2\n",
        "\n",
        "# Calculate Accuracy\n",
        "ensemble_accuracy = accuracy_score(y_val, ensemble_predictions)\n",
        "print(\"Ensemble Accuracy:\", ensemble_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7W0t7Lb84ei"
      },
      "outputs": [],
      "source": [
        "# Step 5: Combine Predictions\n",
        "# Voting Ensemble (Simple Majority Voting)\n",
        "ensemble_predictions = (rf_pred + lr_pred + dt_pred) >= 2\n",
        "ensemble_accuracy = accuracy_score(y_val, ensemble_predictions)\n",
        "print(\"Ensemble Accuracy:\", ensemble_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "En-2CcwaFx6g"
      },
      "outputs": [],
      "source": [
        "e'''from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(tfidf_matrix, train_data['subtask_a'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE to oversample the minority class\n",
        "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "random_forest_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=random_forest_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Get the best model from grid search\n",
        "best_random_forest_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred_val = best_random_forest_model.predict(X_val)\n",
        "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
        "print(\"Validation Accuracy:\", accuracy_val)\n",
        "\n",
        "# Predict labels for the training set\n",
        "y_pred_train = best_random_forest_model.predict(X_resampled)\n",
        "accuracy_train = accuracy_score(y_resampled, y_pred_train)\n",
        "print(\"Training Accuracy:\", accuracy_train)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3_VBT-MGK4r"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''Support Vector Classifier\n",
        "# Split the data into training and validation sets\n",
        "X_train_svm, X_val_svm, y_train_svm, y_val_svm = train_test_split(tfidf_matrix, train_data['subtask_a'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE to oversample the minority class\n",
        "smote_svm = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "X_resampled_svm, y_resampled_svm = smote_svm.fit_resample(X_train_svm, y_train_svm)\n",
        "\n",
        "# Initialize SVM classifier\n",
        "svm_model = SVC(random_state=42)\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_resampled_svm, y_resampled_svm)\n",
        "\n",
        "# Get the best model from grid search\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred_val_svm = best_svm_model.predict(X_val_svm)\n",
        "accuracy_val_svm = accuracy_score(y_val_svm, y_pred_val_svm)\n",
        "print(\"Validation Accuracy:\", accuracy_val_svm)\n",
        "\n",
        "# Predict labels for the training set\n",
        "y_pred_train_svm = best_svm_model.predict(X_resampled_svm)\n",
        "accuracy_train_svm = accuracy_score(y_resampled_svm, y_pred_train_svm)\n",
        "print(\"Training Accuracy:\", accuracy_train_svm)'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwiK84vfIiAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b15f88a-4b79-4444-f7c8-7c5d6cef39bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 5000, 128)         640000    \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 5000, 128)         0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               91600     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 731701 (2.79 MB)\n",
            "Trainable params: 731701 (2.79 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "  4/221 [..............................] - ETA: 1:10:56 - loss: 0.6929 - accuracy: 0.5039"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, SpatialDropout1D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Split the upsampled data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the maximum sequence length\n",
        "max_len = X_train.shape[1]  # Assuming X_train is a matrix of shape (num_samples, max_features)\n",
        "\n",
        "# Convert string labels to numerical format\n",
        "y_train = y_train.map({'OFF': 1, 'NOT': 0})\n",
        "y_test = y_test.map({'OFF': 1, 'NOT': 0})\n",
        "\n",
        "# Define the RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_len))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "print(model.summary())\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train.values, y_train.values, epochs=5, batch_size=64, validation_data=(X_test, y_test), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyJVQuahKmKe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Flatten\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO8kRSK3Kq04"
      },
      "outputs": [],
      "source": [
        "# Convert TF-IDF matrix to array\n",
        "X_features = tfidf_matrix.toarray()\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y_downsampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the data for CNN input (3D tensor required)\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsHYjN0iKqoY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNEEFA4Kbgf_"
      },
      "source": [
        "TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "W5LO-Nl0TkPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f2ceb5-00a0-4c7f-ffb9-5677061edcb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of         id                                              tweet class_a\n",
            "0    15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...     OFF\n",
            "1    27014  #ConstitutionDay is revered by Conservatives, ...     NOT\n",
            "2    30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...     NOT\n",
            "3    13876  #Watching #Boomer getting the news that she is...     NOT\n",
            "4    60133  #NoPasaran: Unity demo to oppose the far-right...     OFF\n",
            "..     ...                                                ...     ...\n",
            "855  73439  #DespicableDems lie again about rifles. Dem Di...     OFF\n",
            "856  25657  #MeetTheSpeakers 🙌 @USER will present in our e...     NOT\n",
            "857  67018  3 people just unfollowed me for talking about ...     OFF\n",
            "858  50665  #WednesdayWisdom Antifa calls the right fascis...     NOT\n",
            "859  24583      #Kavanaugh typical #liberals , #Democrats URL     NOT\n",
            "\n",
            "[860 rows x 3 columns]>\n"
          ]
        }
      ],
      "source": [
        "#Read tweets from test sets\n",
        "test_tweet_a=pd.read_csv(\"/content/drive/MyDrive/testset-levela.tsv\", delimiter='\\t', encoding='utf-8')\n",
        "\n",
        "#Read tweet labels\n",
        "test_label_a=pd.read_csv('/content/drive/MyDrive/labels-levela.csv', names=['id', 'class_a'])\n",
        "\n",
        "#Merge tweets with labels by id\n",
        "test_tweet_a = test_tweet_a.merge(test_label_a, on='id')\n",
        "\n",
        "print(test_tweet_a.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIlXZlAvcd8G"
      },
      "outputs": [],
      "source": [
        "# Clean the tweets in the testing dataset\n",
        "clean_tweets(test_tweet_a)\n",
        "\n",
        "# Tokenize the cleaned tweets\n",
        "tokenized_test_tweets = tokenize_tweets(test_tweet_a['tweet'])\n",
        "\n",
        "# Lemmatize the tokenized tweets (if needed)\n",
        "lemmatized_test_tweets = lemmatize_tweets(tokenized_test_tweets)\n",
        "\n",
        "# Convert the lemmatized tweets back to strings\n",
        "lemmatized_test_tweet_strings = [' '.join(tokens) for tokens in lemmatized_test_tweets]\n",
        "\n",
        "# Vectorize the lemmatized tweet strings using TF-IDF\n",
        "test_tfidf_matrix, _ = tfidf_vectorize_tweets(lemmatized_test_tweet_strings)\n",
        "\n",
        "# Predict labels for the testing set\n",
        "y_pred_test = logistic_model.predict(test_tfidf_matrix)\n",
        "\n",
        "# Print the predicted labels\n",
        "print(\"Predicted Labels:\", y_pred_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "2gcEl0qBdRpS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72deaf78-1006-4818-99d3-79eff2bae68b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.622093023255814\n"
          ]
        }
      ],
      "source": [
        "y_true_test = test_tweet_a['class_a']\n",
        "accuracy_test = accuracy_score(y_true_test, y_pred_test)\n",
        "print(\"Test Accuracy:\", accuracy_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "RckN51wYEIJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13086386-5568-4d49-fcfc-641fbe89bbf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Labels: ['NOT' 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT'\n",
            " 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT'\n",
            " 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'OFF' 'OFF' 'NOT'\n",
            " 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'OFF' 'OFF'\n",
            " 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'OFF' 'NOT' 'OFF' 'OFF' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF'\n",
            " 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'OFF' 'OFF' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'OFF' 'NOT'\n",
            " 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'OFF'\n",
            " 'NOT' 'NOT' 'OFF' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'OFF' 'OFF' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT'\n",
            " 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'OFF' 'NOT'\n",
            " 'NOT' 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'OFF' 'OFF' 'NOT'\n",
            " 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'OFF'\n",
            " 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'OFF'\n",
            " 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'OFF' 'OFF' 'OFF' 'NOT'\n",
            " 'OFF' 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT'\n",
            " 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'OFF' 'NOT'\n",
            " 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'OFF' 'OFF' 'NOT' 'OFF' 'OFF' 'OFF' 'NOT'\n",
            " 'OFF' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'OFF'\n",
            " 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'OFF'\n",
            " 'NOT' 'OFF' 'NOT' 'OFF' 'OFF' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'OFF' 'NOT' 'OFF' 'NOT'\n",
            " 'OFF' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'OFF' 'OFF' 'OFF' 'NOT' 'OFF'\n",
            " 'OFF' 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'OFF' 'NOT' 'OFF' 'OFF'\n",
            " 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT'\n",
            " 'OFF' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'OFF' 'OFF' 'OFF' 'NOT'\n",
            " 'NOT' 'NOT' 'OFF' 'OFF' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF'\n",
            " 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF'\n",
            " 'OFF' 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'OFF' 'OFF' 'OFF' 'NOT' 'NOT' 'NOT'\n",
            " 'OFF' 'NOT' 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT'\n",
            " 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'OFF' 'OFF' 'OFF' 'NOT'\n",
            " 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'NOT'\n",
            " 'OFF' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF'\n",
            " 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'OFF' 'OFF' 'OFF' 'OFF' 'OFF' 'OFF' 'NOT' 'NOT' 'OFF' 'NOT'\n",
            " 'NOT' 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'OFF' 'NOT'\n",
            " 'NOT' 'NOT' 'OFF' 'NOT' 'OFF' 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'OFF' 'NOT'\n",
            " 'NOT' 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'OFF' 'OFF'\n",
            " 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF'\n",
            " 'NOT' 'OFF' 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'OFF' 'OFF' 'NOT'\n",
            " 'NOT' 'OFF' 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'OFF'\n",
            " 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT'\n",
            " 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'NOT'\n",
            " 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'NOT' 'NOT' 'NOT'\n",
            " 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'OFF' 'NOT' 'OFF' 'OFF' 'OFF' 'NOT' 'NOT'\n",
            " 'NOT' 'OFF' 'NOT' 'NOT' 'OFF' 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'OFF' 'NOT'\n",
            " 'NOT' 'NOT' 'OFF' 'NOT' 'NOT' 'OFF' 'NOT' 'NOT']\n",
            "Test Accuracy: 0.5604651162790698\n"
          ]
        }
      ],
      "source": [
        "# Predict labels for the testing set\n",
        "y_rf_test = random_forest_model.predict(test_tfidf_matrix)\n",
        "\n",
        "# Print the predicted labels\n",
        "print(\"Predicted Labels:\", y_rf_test)\n",
        "y_true_test_rf = test_tweet_a['class_a']\n",
        "accuracy_test_rf = accuracy_score(y_true_test_rf, y_rf_test)\n",
        "print(\"Test Accuracy:\", accuracy_test_rf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_data = pd.read_csv(\"/content/custom_tweet.csv\")"
      ],
      "metadata": {
        "id": "x4p26G14zh9f"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the tweets in the testing dataset\n",
        "clean_tweets(custom_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "thrXL6Xk16Vu",
        "outputId": "baff1ce4-5ed1-4443-f567-0b522297f62f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-0e83b4979b94>:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  .str.replace('\\d+','') \\\n",
            "<ipython-input-9-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               tweet labels_self  Unnamed: 2  \\\n",
              "0  blyatnsky army run fuck fucking slow ukraine m...         OFF         NaN   \n",
              "1                        dont get tell sad well fuck         OFF         NaN   \n",
              "2  chelseas insecurities drove put one sided comp...         OFF         NaN   \n",
              "3  nah islanders pussies need admit think georgia...         OFF         NaN   \n",
              "4  hello im private jet cook clean im studying fe...         NOT         NaN   \n",
              "5                          guys sending ndes dms wtf         OFF         NaN   \n",
              "6  met fabulous entrepreneur lunch rachana ranade...         NOT         NaN   \n",
              "7  bicycle race ocean different animals athletes ...         NOT         NaN   \n",
              "8  hot people complete whole syllabus one night exam         NOT         NaN   \n",
              "9  dont need apologise bhai things part parcel ga...         NOT         NaN   \n",
              "\n",
              "   Unnamed: 3  Unnamed: 4  Unnamed: 5  \n",
              "0         NaN         NaN         NaN  \n",
              "1         NaN         NaN         NaN  \n",
              "2         NaN         NaN         NaN  \n",
              "3         NaN         NaN         NaN  \n",
              "4         NaN         NaN         NaN  \n",
              "5         NaN         NaN         NaN  \n",
              "6         NaN         NaN         NaN  \n",
              "7         NaN         NaN         NaN  \n",
              "8         NaN         NaN         NaN  \n",
              "9         NaN         NaN         NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25428773-bc9d-4898-a2c2-5df6d17da58c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>labels_self</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blyatnsky army run fuck fucking slow ukraine m...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dont get tell sad well fuck</td>\n",
              "      <td>OFF</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>chelseas insecurities drove put one sided comp...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nah islanders pussies need admit think georgia...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hello im private jet cook clean im studying fe...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>guys sending ndes dms wtf</td>\n",
              "      <td>OFF</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>met fabulous entrepreneur lunch rachana ranade...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>bicycle race ocean different animals athletes ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>hot people complete whole syllabus one night exam</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>dont need apologise bhai things part parcel ga...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25428773-bc9d-4898-a2c2-5df6d17da58c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-25428773-bc9d-4898-a2c2-5df6d17da58c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-25428773-bc9d-4898-a2c2-5df6d17da58c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-25dec05e-a00f-42a6-b7dd-72d27096f5a8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25dec05e-a00f-42a6-b7dd-72d27096f5a8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-25dec05e-a00f-42a6-b7dd-72d27096f5a8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "custom_data",
              "summary": "{\n  \"name\": \"custom_data\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"hot people complete whole syllabus one night exam\",\n          \"dont get tell sad well fuck\",\n          \"guys sending ndes dms wtf\"\n        ],\n        \"num_unique_values\": 10,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels_self\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"NOT\",\n          \"OFF\"\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": NaN,\n        \"min\": NaN,\n        \"max\": NaN,\n        \"samples\": [],\n        \"num_unique_values\": 0,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": NaN,\n        \"min\": NaN,\n        \"max\": NaN,\n        \"samples\": [],\n        \"num_unique_values\": 0,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": NaN,\n        \"min\": NaN,\n        \"max\": NaN,\n        \"samples\": [],\n        \"num_unique_values\": 0,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": NaN,\n        \"min\": NaN,\n        \"max\": NaN,\n        \"samples\": [],\n        \"num_unique_values\": 0,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenize the cleaned tweets\n",
        "tokenized_test_tweets_c = tokenize_tweets(custom_data['tweet'])\n",
        "\n",
        "# Lemmatize the tokenized tweets (if needed)\n",
        "lemmatized_test_tweets_c = lemmatize_tweets(tokenized_test_tweets_c)"
      ],
      "metadata": {
        "id": "IEi1HP4x1_IM"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert the lemmatized tweets back to strings\n",
        "lemmatized_test_tweet_strings_c = [' '.join(tokens) for tokens in lemmatized_test_tweets_c]\n",
        "\n"
      ],
      "metadata": {
        "id": "2eDAJex31x-1"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_test_tweet_strings_c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0eWZgyX3geA",
        "outputId": "ed100c8d-b86f-4a7e-94ba-560ba56f7e3a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['blyatnsky army run fuck fucking slow ukraine militant trying leave avdeevka towards village lastochkino field shell falling nearby road damaged equipment unable leave already noticed',\n",
              " 'dont get tell sad well fuck',\n",
              " 'chelseas insecurity drove put one sided competition jessica shes prize gaslighting dickhead who pussy tell he attracted physically mean playing stupid game',\n",
              " 'nah islander pussy need admit think georgia h fake think',\n",
              " 'hello im private jet cook clean im studying feminism love taylor swift lana del rey',\n",
              " 'guy sending ndes dm wtf',\n",
              " 'met fabulous entrepreneur lunch rachana ranade fellow chartered accountant shes super inspiring finfluencer clarity infectious energy',\n",
              " 'bicycle race ocean different animal athlete riding bicycle drone camera view',\n",
              " 'hot people complete whole syllabus one night exam',\n",
              " 'dont need apologise bhai thing part parcel game played exceptional knock today']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_tfidf_matrix_c, _ = tfidf_vectorize_tweets(lemmatized_test_tweet_strings_c)\n",
        "\n"
      ],
      "metadata": {
        "id": "6V48oJ1E2beO"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict labels for the testing set\n",
        "y_pred_test_c = logistic_model.predict(test_tfidf_matrix_c)\n",
        "\n",
        "# Print the predicted labels\n",
        "print(\"Predicted Labels:\", y_pred_test_c)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "WuaSxZ-03FND",
        "outputId": "305ae719-48b7-408d-97b9-7324b4107e7c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "X has 313 features, but LogisticRegression is expecting 5000 features as input.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-d401877fa2eb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predict labels for the testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred_test_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tfidf_matrix_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Print the predicted labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted Labels:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \"\"\"\n\u001b[1;32m    418\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    390\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: X has 313 features, but LogisticRegression is expecting 5000 features as input."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_d20IFj2391p"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}