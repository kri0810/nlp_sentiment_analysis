{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEDyiExAVqLA"
      },
      "outputs": [],
      "source": [
        "#importing necessary libraries\n",
        "import pandas as pd\n",
        "import string\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWBHYXLQHkAv",
        "outputId": "a6057220-a374-438c-d457-4ff7e4420332"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyluCz9q6xYk",
        "outputId": "68d8a27c-36b6-40f6-f17f-1b1eef640c0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "RcFx2KLEVfXs",
        "outputId": "d71d00b9-ab16-435a-85b7-052038b8e5e2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f82915c2-d76f-4803-9f07-b87c701de7b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>subtask_a</th>\n",
              "      <th>subtask_b</th>\n",
              "      <th>subtask_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90194</td>\n",
              "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>TIN</td>\n",
              "      <td>IND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13188</th>\n",
              "      <td>94475</td>\n",
              "      <td>@USER every antifa member is just several midg...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13189</th>\n",
              "      <td>34150</td>\n",
              "      <td>@USER Berkeley Antifa do not agree with you URL</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13190</th>\n",
              "      <td>83400</td>\n",
              "      <td>@USER You are a great model for inspiration</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13191</th>\n",
              "      <td>84081</td>\n",
              "      <td>@USER Chris, Chris, Chris.... Are you forgetti...</td>\n",
              "      <td>OFF</td>\n",
              "      <td>UNT</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13192</th>\n",
              "      <td>11244</td>\n",
              "      <td>@USER Advocate for gun control while breaking ...</td>\n",
              "      <td>NOT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13193 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f82915c2-d76f-4803-9f07-b87c701de7b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f82915c2-d76f-4803-9f07-b87c701de7b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f82915c2-d76f-4803-9f07-b87c701de7b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aa1c3f50-4ecb-4963-9c73-c61df5fe12cd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aa1c3f50-4ecb-4963-9c73-c61df5fe12cd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aa1c3f50-4ecb-4963-9c73-c61df5fe12cd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          id                                              tweet subtask_a  \\\n",
              "0      86426  @USER She should ask a few native Americans wh...       OFF   \n",
              "1      90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
              "2      16820  Amazon is investigating Chinese employees who ...       NOT   \n",
              "3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
              "4      43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
              "...      ...                                                ...       ...   \n",
              "13188  94475  @USER every antifa member is just several midg...       NOT   \n",
              "13189  34150    @USER Berkeley Antifa do not agree with you URL       NOT   \n",
              "13190  83400        @USER You are a great model for inspiration       NOT   \n",
              "13191  84081  @USER Chris, Chris, Chris.... Are you forgetti...       OFF   \n",
              "13192  11244  @USER Advocate for gun control while breaking ...       NOT   \n",
              "\n",
              "      subtask_b subtask_c  \n",
              "0           UNT       NaN  \n",
              "1           TIN       IND  \n",
              "2           NaN       NaN  \n",
              "3           UNT       NaN  \n",
              "4           NaN       NaN  \n",
              "...         ...       ...  \n",
              "13188       NaN       NaN  \n",
              "13189       NaN       NaN  \n",
              "13190       NaN       NaN  \n",
              "13191       UNT       NaN  \n",
              "13192       NaN       NaN  \n",
              "\n",
              "[13193 rows x 5 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#loading the dataset after converting tsv into csv\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/olid-training.csv\")\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "-wuj8KVKJEpq",
        "outputId": "ce3b7a7e-a0da-4fd3-ee1c-6bf0e699ecc8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'from sklearn.utils import resample\\nimport pandas as pd\\n\\n# Separate the majority and minority classes\\nmajority_class = train_data[train_data[\\'subtask_a\\'] == \\'NOT\\']\\nminority_class = train_data[train_data[\\'subtask_a\\'] == \\'OFF\\']\\n\\n# Checking counts of majority and minority classes\\nprint(\"Original Counts - Majority:\", len(majority_class), \"Minority:\", len(minority_class))\\n\\n# Oversample the minority class to match the number of majority class instances\\noversampled_minority = resample(minority_class,\\n                                replace=True,  # Sample with replacement\\n                                n_samples=len(majority_class),  # Match number of majority class instances\\n                                random_state=42)  # Reproducible results\\n\\n# Combine oversampled minority class with majority class\\nbalanced_data = pd.concat([majority_class, oversampled_minority])\\n\\n\\nprint(\"Balanced Data Shape:\", balanced_data.shape)'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''from sklearn.utils import resample\n",
        "import pandas as pd\n",
        "\n",
        "# Separate the majority and minority classes\n",
        "majority_class = train_data[train_data['subtask_a'] == 'NOT']\n",
        "minority_class = train_data[train_data['subtask_a'] == 'OFF']\n",
        "\n",
        "# Checking counts of majority and minority classes\n",
        "print(\"Original Counts - Majority:\", len(majority_class), \"Minority:\", len(minority_class))\n",
        "\n",
        "# Oversample the minority class to match the number of majority class instances\n",
        "oversampled_minority = resample(minority_class,\n",
        "                                replace=True,  # Sample with replacement\n",
        "                                n_samples=len(majority_class),  # Match number of majority class instances\n",
        "                                random_state=42)  # Reproducible results\n",
        "\n",
        "# Combine oversampled minority class with majority class\n",
        "balanced_data = pd.concat([majority_class, oversampled_minority])\n",
        "\n",
        "\n",
        "print(\"Balanced Data Shape:\", balanced_data.shape)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AefCaOq6G8-M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm9GieXLCneL",
        "outputId": "d3886ec1-87bd-4129-ca47-06bf05bc7780"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                   tweet\n",
            "0      @USER She should ask a few native Americans wh...\n",
            "1      @USER @USER Go home you’re drunk!!! @USER #MAG...\n",
            "2      Amazon is investigating Chinese employees who ...\n",
            "3      @USER Someone should'veTaken\" this piece of sh...\n",
            "4      @USER @USER Obama wanted liberals &amp; illega...\n",
            "...                                                  ...\n",
            "13188  @USER every antifa member is just several midg...\n",
            "13189    @USER Berkeley Antifa do not agree with you URL\n",
            "13190        @USER You are a great model for inspiration\n",
            "13191  @USER Chris, Chris, Chris.... Are you forgetti...\n",
            "13192  @USER Advocate for gun control while breaking ...\n",
            "\n",
            "[13193 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "#displaying the tweets\n",
        "train_tweets = train_data[[\"tweet\"]]\n",
        "print(train_tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-qMUz75HUvu",
        "outputId": "b90a302b-6988-4148-cf0c-2b5e3b6fefa9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " #checking for duplicate tweets\n",
        " train_data[\"tweet\"].duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcZ6Lh-vJG_a",
        "outputId": "48706bf7-d05a-4448-e472-10386172f2ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "subtask_a\n",
              "NOT          8804\n",
              "OFF          4389\n",
              "dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#value counts of subtask a after balancing\n",
        "train_data[['subtask_a']].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z8e8QI5V7gt",
        "outputId": "4c979775-4044-4fc0-8a5f-1fd1a366a6b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          id                                              tweet subtask_a  \\\n",
            "0      86426  @USER She should ask a few native Americans wh...       OFF   \n",
            "1      90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
            "2      16820  Amazon is investigating Chinese employees who ...       NOT   \n",
            "3      62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
            "4      43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
            "...      ...                                                ...       ...   \n",
            "13188  94475  @USER every antifa member is just several midg...       NOT   \n",
            "13189  34150    @USER Berkeley Antifa do not agree with you URL       NOT   \n",
            "13190  83400        @USER You are a great model for inspiration       NOT   \n",
            "13191  84081  @USER Chris, Chris, Chris.... Are you forgetti...       OFF   \n",
            "13192  11244  @USER Advocate for gun control while breaking ...       NOT   \n",
            "\n",
            "      subtask_b subtask_c  \n",
            "0           UNT       NaN  \n",
            "1           TIN       IND  \n",
            "2           NaN       NaN  \n",
            "3           UNT       NaN  \n",
            "4           NaN       NaN  \n",
            "...         ...       ...  \n",
            "13188       NaN       NaN  \n",
            "13189       NaN       NaN  \n",
            "13190       NaN       NaN  \n",
            "13191       UNT       NaN  \n",
            "13192       NaN       NaN  \n",
            "\n",
            "[13193 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "train_task_a_labels= train_data[['subtask_a']] #Extract subtsak_a labels\n",
        "train_task_b_labels= train_data[['subtask_b']] #Extract subtsak_b labels\n",
        "train_task_c_labels= train_data[['subtask_c']] #Extract subtsak_c labels\n",
        "\n",
        "train_task_a_labels.columns.values[0] = 'class_a' #Rename class attribute\n",
        "train_task_b_labels.columns.values[0] = 'class_b' #Rename class attribute\n",
        "train_task_c_labels.columns.values[0] = 'class_c' #Rename class attribute\n",
        "\n",
        "print(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bAuiH5SacZC"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def clean_tweets(df):\n",
        "    punctuations = string.punctuation\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Remove mentions, URLs, and special characters\n",
        "    df.loc[:, 'tweet'] = df.tweet.str.replace('@USER', '') \\\n",
        "                                    .str.replace('URL', '') \\\n",
        "                                    .str.replace('&amp', 'and') \\\n",
        "                                    .str.replace('&lt','') \\\n",
        "                                    .str.replace('&gt','') \\\n",
        "                                    .str.replace('\\d+','') \\\n",
        "                                    .str.lower()\n",
        "\n",
        "    # Remove punctuations\n",
        "    for punctuation in punctuations:\n",
        "        df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
        "\n",
        "    # Remove emojis\n",
        "    df.loc[:, 'tweet'] = df.tweet.apply(lambda x: re.sub(r'[^\\x00-\\x7F]+', '', x))\n",
        "\n",
        "    # Remove stopwords\n",
        "    df.loc[:, 'tweet'] = df.tweet.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "\n",
        "    # Trim leading and trailing whitespaces\n",
        "    df.loc[:, 'tweet'] = df.tweet.str.strip()\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUSlrFGn0vPx",
        "outputId": "d24e03aa-c33b-42ac-d7b8-2e91a7178957"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-tgyiB5rW3qL",
        "outputId": "15276e3b-6640-402b-d7d8-e5507104ae0d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-0e83b4979b94>:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  .str.replace('\\d+','') \\\n",
            "<ipython-input-10-0e83b4979b94>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace('@USER', '') \\\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.replace(punctuation, '')\n",
            "<ipython-input-10-0e83b4979b94>:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.apply(lambda x: re.sub(r'[^\\x00-\\x7F]+', '', x))\n",
            "<ipython-input-10-0e83b4979b94>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
            "<ipython-input-10-0e83b4979b94>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, 'tweet'] = df.tweet.str.strip()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4621ea9a-0935-45a2-af6d-5358e625080c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ask native americans take</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>go home youre drunk maga trump</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amazon investigating chinese employees selling...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>someone shouldvetaken piece shit volcano</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>obama wanted liberals illegals move red states</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13188</th>\n",
              "      <td>every antifa member several midget gypsies sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13189</th>\n",
              "      <td>berkeley antifa agree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13190</th>\n",
              "      <td>great model inspiration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13191</th>\n",
              "      <td>chris chris chris forgetting mantra every sing...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13192</th>\n",
              "      <td>advocate gun control breaking current gun laws...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13193 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4621ea9a-0935-45a2-af6d-5358e625080c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4621ea9a-0935-45a2-af6d-5358e625080c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4621ea9a-0935-45a2-af6d-5358e625080c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4db11adb-0c1c-4bf9-a669-ff70a43af6b5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4db11adb-0c1c-4bf9-a669-ff70a43af6b5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4db11adb-0c1c-4bf9-a669-ff70a43af6b5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                   tweet\n",
              "0                              ask native americans take\n",
              "1                         go home youre drunk maga trump\n",
              "2      amazon investigating chinese employees selling...\n",
              "3               someone shouldvetaken piece shit volcano\n",
              "4         obama wanted liberals illegals move red states\n",
              "...                                                  ...\n",
              "13188  every antifa member several midget gypsies sta...\n",
              "13189                              berkeley antifa agree\n",
              "13190                            great model inspiration\n",
              "13191  chris chris chris forgetting mantra every sing...\n",
              "13192  advocate gun control breaking current gun laws...\n",
              "\n",
              "[13193 rows x 1 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_tweets(train_tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-iF5dt2W68i"
      },
      "outputs": [],
      "source": [
        "train_task_a_data = train_tweets.join(train_task_a_labels)\n",
        "\n",
        "train_task_b_data = train_tweets.join(train_task_b_labels)\n",
        "train_task_b_data = train_task_b_data.dropna() #Drop records with missing values\n",
        "\n",
        "train_task_c_data = train_tweets.join(train_task_c_labels)\n",
        "train_task_c_data = train_task_c_data.dropna() #Drop records with missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9NGkzKjdyjk",
        "outputId": "19dc75b0-0cee-41ae-eb69-ef94df62a4e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tweet 1: ['ask', 'native', 'americans', 'take']\n",
            "Tweet 2: ['go', 'home', 'youre', 'drunk', 'maga', 'trump']\n",
            "Tweet 3: ['amazon', 'investigating', 'chinese', 'employees', 'selling', 'internal', 'data', 'thirdparty', 'sellers', 'looking', 'edge', 'competitive', 'marketplace', 'amazon', 'maga', 'kag', 'china', 'tcot']\n",
            "Tweet 4: ['someone', 'shouldvetaken', 'piece', 'shit', 'volcano']\n",
            "Tweet 5: ['obama', 'wanted', 'liberals', 'illegals', 'move', 'red', 'states']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def tokenize_tweets(tweets):\n",
        "\n",
        "    tokenized_tweets = [word_tokenize(tweet) for tweet in tweets]\n",
        "    return tokenized_tweets\n",
        "\n",
        "\n",
        "#  train_tweets['tweet'] contains the list of tweets\n",
        "tweets = train_tweets['tweet']\n",
        "tokenized_tweets = tokenize_tweets(tweets)\n",
        "\n",
        "# Printing the first few tokenized tweets for verification\n",
        "for i in range(5):  # Print the first 5 tokenized tweets\n",
        "    print(f\"Tweet {i + 1}: {tokenized_tweets[i]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6iqLAtmwy3C",
        "outputId": "5b241cd3-7397-41f0-ebda-a812942b8c98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lemmatized Tweet 1: ['ask', 'native', 'american', 'take']\n",
            "Lemmatized Tweet 2: ['go', 'home', 'youre', 'drunk', 'maga', 'trump']\n",
            "Lemmatized Tweet 3: ['amazon', 'investigating', 'chinese', 'employee', 'selling', 'internal', 'data', 'thirdparty', 'seller', 'looking', 'edge', 'competitive', 'marketplace', 'amazon', 'maga', 'kag', 'china', 'tcot']\n",
            "Lemmatized Tweet 4: ['someone', 'shouldvetaken', 'piece', 'shit', 'volcano']\n",
            "Lemmatized Tweet 5: ['obama', 'wanted', 'liberal', 'illegals', 'move', 'red', 'state']\n",
            "13193\n"
          ]
        }
      ],
      "source": [
        "#Lemmatization preserves the semantic meaning of words better than stemming and is less likely to introduce non-standard words.\n",
        "# lemmatization also considers different POS tags\n",
        "#lemm using nltk\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def lemmatize_tweets(tokenized_tweets):\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tweets = []\n",
        "    for tweet_tokens in tokenized_tweets:\n",
        "        lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tweet_tokens]\n",
        "        lemmatized_tweets.append(lemmatized_tokens)\n",
        "    return lemmatized_tweets\n",
        "\n",
        "# Assuming tokenized_tweets contains the list of tokenized tweets\n",
        "lemmatized_tweets = lemmatize_tweets(tokenized_tweets)\n",
        "\n",
        "# Printing the first few lemmatized tweets for verification\n",
        "for i in range(5):  # Print the first 5 lemmatized tweets\n",
        "    print(f\"Lemmatized Tweet {i + 1}: {lemmatized_tweets[i]}\")\n",
        "print(len(lemmatized_tweets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j42KF1neOZP4",
        "outputId": "55264649-3958-4d36-c2dc-79ab18d07a64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                                ask native americans take\n",
              "1                           go home youre drunk maga trump\n",
              "2        amazon investigating chinese employees selling...\n",
              "3                 someone shouldvetaken piece shit volcano\n",
              "4           obama wanted liberals illegals move red states\n",
              "                               ...                        \n",
              "13188    every antifa member several midget gypsies sta...\n",
              "13189                                berkeley antifa agree\n",
              "13190                              great model inspiration\n",
              "13191    chris chris chris forgetting mantra every sing...\n",
              "13192    advocate gun control breaking current gun laws...\n",
              "Name: tweet, Length: 13193, dtype: object"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_tweets[\"tweet\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "NLEcKftQMPas",
        "outputId": "82c40dce-7778-41bc-8f57-982fc4d7c956"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"#word cloud after pre-processing\\nfrom nltk.stem import WordNetLemmatizer\\nfrom wordcloud import WordCloud\\nimport matplotlib.pyplot as plt\\n\\n# Sample lemmatized_tweets data (replace it with your actual lemmatized tweets)\\nlemmatized_tweets =[ train_tweets['tweet']]\\n\\n# Initialize the WordNetLemmatizer\\nlemmatizer = WordNetLemmatizer()\\n\\n# Combine all lemmatized tokens into a single text corpus\\ntext_corpus = ' '.join([' '.join([lemmatizer.lemmatize(token) for token in tweet_tokens]) for tweet_tokens in lemmatized_tweets])\\n\\n# Generate the word cloud\\nwordcloud = WordCloud(width=800, height=400, background_color='white').generate(text_corpus)\\n\\n# Display the word cloud using matplotlib\\nplt.figure(figsize=(10, 6))\\nplt.imshow(wordcloud, interpolation='bilinear')\\nplt.axis('off')\\nplt.show()\\n\""
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''#word cloud after pre-processing\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample lemmatized_tweets data (replace it with your actual lemmatized tweets)\n",
        "lemmatized_tweets =[ train_tweets['tweet']]\n",
        "\n",
        "# Initialize the WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Combine all lemmatized tokens into a single text corpus\n",
        "text_corpus = ' '.join([' '.join([lemmatizer.lemmatize(token) for token in tweet_tokens]) for tweet_tokens in lemmatized_tweets])\n",
        "\n",
        "# Generate the word cloud\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text_corpus)\n",
        "\n",
        "# Display the word cloud using matplotlib\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mQTD7isep2E",
        "outputId": "4d2c6bb9-ad20-4dd2-8542-93458a42dc95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF Matrix:\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            "Feature Names:\n",
            "['aaron' 'ab' 'abiding' ... 'zero evidence' 'zombie' 'zone']\n",
            "(13193, 5000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def tfidf_vectorize_tweets(tweets, max_features=5000, ngram_range=(1, 3), stop_words='english'):\n",
        "\n",
        "    # Initialize the TfidfVectorizer with desired parameters\n",
        "    tfidf_vectorizer = TfidfVectorizer(max_features=max_features, stop_words=stop_words, ngram_range=ngram_range)\n",
        "\n",
        "    # Fit the vectorizer to the tweets and transform them into TF-IDF vectors\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(tweets)\n",
        "\n",
        "    # Get the feature names (words) from the vectorizer\n",
        "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "    return tfidf_matrix, feature_names\n",
        "\n",
        "# Example usage:\n",
        "# Assuming lemmatized_tweet_strings contains the list of lemmatized tweet strings\n",
        "lemmatized_tweet_strings = [' '.join(tokens) for tokens in lemmatized_tweets]\n",
        "tfidf_matrix, feature_names = tfidf_vectorize_tweets(lemmatized_tweet_strings)\n",
        "\n",
        "# Print the TF-IDF matrix and feature names\n",
        "print(\"TF-IDF Matrix:\")\n",
        "print(tfidf_matrix.toarray())\n",
        "print(\"\\nFeature Names:\")\n",
        "print(feature_names)\n",
        "print(tfidf_matrix.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "-BvAM4ub3Tkn",
        "outputId": "13d43e34-3b28-4b5e-8e55-6fdbc579d925"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'vectorization using tfidf\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\n\\n# Convert the lemmatized tweets back to strings\\nlemmatized_tweet_strings = [\\' \\'.join(tokens) for tokens in lemmatized_tweets]\\n\\n# Initializing the TfidfVectorizer with desired parameters\\ntfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=\\'english\\', ngram_range=(1, 3))\\n\\n# Fit the vectorizer to the lemmatized tweets and transform them into TF-IDF vectors\\ntfidf_matrix = tfidf_vectorizer.fit_transform(lemmatized_tweet_strings)\\n\\n# Get the feature names (words) from the vectorizer\\nfeature_names = tfidf_vectorizer.get_feature_names_out()\\n\\n# Print the TF-IDF matrix and feature names\\nprint(\"TF-IDF Matrix:\")\\nprint(tfidf_matrix.toarray())\\nprint(\"\\nFeature Names:\")\\nprint(feature_names)\\n\\nprint(tfidf_matrix.shape)'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''vectorization using tfidf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Convert the lemmatized tweets back to strings\n",
        "lemmatized_tweet_strings = [' '.join(tokens) for tokens in lemmatized_tweets]\n",
        "\n",
        "# Initializing the TfidfVectorizer with desired parameters\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 3))\n",
        "\n",
        "# Fit the vectorizer to the lemmatized tweets and transform them into TF-IDF vectors\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(lemmatized_tweet_strings)\n",
        "\n",
        "# Get the feature names (words) from the vectorizer\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Print the TF-IDF matrix and feature names\n",
        "print(\"TF-IDF Matrix:\")\n",
        "print(tfidf_matrix.toarray())\n",
        "print(\"\\nFeature Names:\")\n",
        "print(feature_names)\n",
        "\n",
        "print(tfidf_matrix.shape)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4VMpvWCMBYK",
        "outputId": "06dda927-1736-4d4b-ad99-9ed7bc9ea0b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8778,)\n"
          ]
        }
      ],
      "source": [
        "#undersampling using Resample library\n",
        "combined_data = pd.concat([pd.DataFrame(tfidf_matrix.toarray()), train_data['subtask_a']], axis=1)\n",
        "\n",
        "# Separate majority and minority classes\n",
        "majority_class = combined_data[combined_data['subtask_a'] == 'NOT']\n",
        "minority_class = combined_data[combined_data['subtask_a'] == 'OFF']\n",
        "\n",
        "# Upsample minority class\n",
        "majority_downsampled = resample(majority_class,\n",
        "                               replace=False,  # Sample with replacement\n",
        "                               n_samples=len(minority_class),  # Match number in majority class\n",
        "                               random_state=42)  # Reproducible results\n",
        "\n",
        "# Combine majority class with upsampled minority class\n",
        "downsampled_data = pd.concat([majority_downsampled, minority_class])\n",
        "\n",
        "# Separate features (TF-IDF matrix) and labels\n",
        "X_downsampled = downsampled_data.drop('subtask_a', axis=1)\n",
        "y_downsampled = downsampled_data['subtask_a']\n",
        "print(downsampled_data['subtask_a'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvlEqIpFnk78",
        "outputId": "79f21195-3f07-46c0-b769-db18afab8be9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.10.2-py3-none-any.whl (19.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Collecting gitpython<4,>=2.1.0 (from mlflow)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pytz<2024 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.4)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: packaging<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.2)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.0.1)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4.4)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.23.5)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.3)\n",
            "Collecting querystring-parser<2 (from mlflow)\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.25)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: pyarrow<16,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (10.0.1)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.5.2)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Collecting gunicorn<22 (from mlflow)\n",
            "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.3)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.9.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.0.7)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.1.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from querystring-parser<2->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.2.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, querystring-parser, Mako, gunicorn, gitdb, docker, alembic, gitpython, mlflow\n",
            "Successfully installed Mako-1.3.2 alembic-1.13.1 docker-7.0.0 gitdb-4.0.11 gitpython-3.1.41 gunicorn-21.2.0 mlflow-2.10.2 querystring-parser-1.2.4 smmap-5.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwFFUdNJngSF"
      },
      "outputs": [],
      "source": [
        "import mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHXMpihdPGrs"
      },
      "outputs": [],
      "source": [
        "with mlflow.start_run():\n",
        "    # Add parameters\n",
        "    mlflow.log_param(\"C\", 1)\n",
        "    mlflow.log_param(\"penalty\", 'l2')\n",
        "    mlflow.log_param(\"random_state\", 42)\n",
        "#Split the upsampled data into training and testing sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_downsampled, y_downsampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the logistic regression model\n",
        "logistic_model = LogisticRegression(C = 1, penalty = 'l2',random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict labels for the testing data\n",
        "lr_pred = logistic_model.predict(X_val)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, lr_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "#printing classification report\n",
        "print(classification_report(y_val, lr_pred, output_dict=True))\n",
        "for class_label, metrics in classification_rep.items():\n",
        "        for metric_name, metric_value in metrics.items():\n",
        "            mlflow.log_metric(f\"{class_label}_{metric_name}\", metric_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "veA6mbdO4YRg",
        "outputId": "8580ae41-a332-4a45-d685-1e50fe599ac7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Apply SMOTE to oversample the majority class\\nsmote = SMOTE(sampling_strategy=\\'minority\\', random_state=42)\\nX_resampled, y_resampled = smote.fit_resample(tfidf_matrix, train_data[\\'subtask_a\\'])\\n\\n# Split the resampled TF-IDF matrix and labels into train and validation sets\\nX_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\\n\\n# Initialize and fit the logistic regression model\\nlogistic_model = LogisticRegression(max_iter=1000)  # Increase max_iter if needed\\nlogistic_model.fit(X_train, y_train)\\n\\n# Predicting labels for the validation set\\ny_pred_val = logistic_model.predict(X_val)\\n\\n# Calculate accuracy score for validation set\\naccuracy_val = accuracy_score(y_val, y_pred_val)\\nprint(\"Validation Accuracy:\", accuracy_val)\\n\\n# Predicting labels for the training set\\ny_pred_train = logistic_model.predict(X_train)\\n\\n# Calculate accuracy score for training set\\naccuracy_train = accuracy_score(y_train, y_pred_train)\\nprint(\"Training Accuracy:\", accuracy_train)'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "'''\n",
        "# Apply SMOTE to oversample the majority class\n",
        "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(tfidf_matrix, train_data['subtask_a'])\n",
        "\n",
        "# Split the resampled TF-IDF matrix and labels into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and fit the logistic regression model\n",
        "logistic_model = LogisticRegression(max_iter=1000)  # Increase max_iter if needed\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting labels for the validation set\n",
        "y_pred_val = logistic_model.predict(X_val)\n",
        "\n",
        "# Calculate accuracy score for validation set\n",
        "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
        "print(\"Validation Accuracy:\", accuracy_val)\n",
        "\n",
        "# Predicting labels for the training set\n",
        "y_pred_train = logistic_model.predict(X_train)\n",
        "\n",
        "# Calculate accuracy score for training set\n",
        "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
        "print(\"Training Accuracy:\", accuracy_train)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMgtfQeLBW2l",
        "outputId": "3cb408d0-8adf-4e37-f8f3-21166e187ce6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training Accuracy: 0.7491474043198181\n",
            "testing Accuracy: 0.8082243699071442\n"
          ]
        }
      ],
      "source": [
        "#lr model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have labels associated with your lemmatized tweets\n",
        "# Replace 'labels' with the actual labels from your dataset\n",
        "\n",
        "# Split the TF-IDF matrix and labels into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(tfidf_matrix, train_data['subtask_a'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and fit the logistic regression model\n",
        "logistic_model = LogisticRegression(max_iter=1000)  # Increase max_iter if needed\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting labels for the validation set\n",
        "lr_pred = logistic_model.predict(X_val)\n",
        "\n",
        "# accuracy score for validation set\n",
        "accuracy = accuracy_score(y_val, lr_pred)\n",
        "print(\"training Accuracy:\", accuracy)\n",
        "\n",
        "# Predicting labels for the training set\n",
        "y_pred_tr = logistic_model.predict(X_train)\n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy = accuracy_score(y_train, y_pred_tr)\n",
        "print(\"testing Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7JNFS8yDtNZ",
        "outputId": "358b835a-b718-4354-ac5c-6d8cad79fe9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_Accuracy: 0.6964692482915718\n",
            "train_Accuracy: 0.9891768726858445\n"
          ]
        }
      ],
      "source": [
        "#rf model\n",
        "\n",
        "\n",
        "# Split the TF-IDF matrix and labels into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_downsampled, y_downsampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and fit the Random Forest classifier\n",
        "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict labels for the validation set\n",
        "rf_pred = random_forest_model.predict(X_val)\n",
        "\n",
        "# Calculated accuracy score\n",
        "accuracy = accuracy_score(y_val, rf_pred)\n",
        "print(\"val_Accuracy:\", accuracy)\n",
        "\n",
        "# Predict labels for the training set\n",
        "y_pred_train = random_forest_model.predict(X_train)\n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
        "print(\"train_Accuracy:\", accuracy_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_colVur7Hby",
        "outputId": "ef99566a-df55-4bf5-8fcf-71edc8bac16c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6503416856492027\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# Initialize and fit the Random Forest classifier\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "dt_pred = dt_model.predict(X_val)\n",
        "acc = accuracy_score(y_val, dt_pred)\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngVogKSgALHl"
      },
      "outputs": [],
      "source": [
        "# Convert predictions to binary (0 or 1) if they are not already\n",
        "rf_pred = random_forest_model.predict_proba(X_val)[:, 1]  # Assuming you want the probability of the positive class\n",
        "lr_pred = logistic_model.predict_proba(X_val)[:, 1]\n",
        "dt_pred = dt_model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "# Convert probabilities to binary predictions using a threshold of 0.5\n",
        "rf_pred_binary = (rf_pred >= 0.5).astype(int)\n",
        "lr_pred_binary = (lr_pred >= 0.5).astype(int)\n",
        "dt_pred_binary = (dt_pred >= 0.5).astype(int)\n",
        "\n",
        "# Combine predictions using simple majority voting\n",
        "ensemble_predictions = (rf_pred_binary + lr_pred_binary + dt_pred_binary) >= 2\n",
        "\n",
        "# Calculate Accuracy\n",
        "ensemble_accuracy = accuracy_score(y_val, ensemble_predictions)\n",
        "print(\"Ensemble Accuracy:\", ensemble_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7W0t7Lb84ei"
      },
      "outputs": [],
      "source": [
        "# Step 5: Combine Predictions\n",
        "# Voting Ensemble (Simple Majority Voting)\n",
        "ensemble_predictions = (rf_pred + lr_pred + dt_pred) >= 2\n",
        "ensemble_accuracy = accuracy_score(y_val, ensemble_predictions)\n",
        "print(\"Ensemble Accuracy:\", ensemble_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "En-2CcwaFx6g"
      },
      "outputs": [],
      "source": [
        "e'''from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(tfidf_matrix, train_data['subtask_a'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE to oversample the minority class\n",
        "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "random_forest_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=random_forest_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Get the best model from grid search\n",
        "best_random_forest_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred_val = best_random_forest_model.predict(X_val)\n",
        "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
        "print(\"Validation Accuracy:\", accuracy_val)\n",
        "\n",
        "# Predict labels for the training set\n",
        "y_pred_train = best_random_forest_model.predict(X_resampled)\n",
        "accuracy_train = accuracy_score(y_resampled, y_pred_train)\n",
        "print(\"Training Accuracy:\", accuracy_train)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3_VBT-MGK4r"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''Support Vector Classifier\n",
        "# Split the data into training and validation sets\n",
        "X_train_svm, X_val_svm, y_train_svm, y_val_svm = train_test_split(tfidf_matrix, train_data['subtask_a'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE to oversample the minority class\n",
        "smote_svm = SMOTE(sampling_strategy='minority', random_state=42)\n",
        "X_resampled_svm, y_resampled_svm = smote_svm.fit_resample(X_train_svm, y_train_svm)\n",
        "\n",
        "# Initialize SVM classifier\n",
        "svm_model = SVC(random_state=42)\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_resampled_svm, y_resampled_svm)\n",
        "\n",
        "# Get the best model from grid search\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_pred_val_svm = best_svm_model.predict(X_val_svm)\n",
        "accuracy_val_svm = accuracy_score(y_val_svm, y_pred_val_svm)\n",
        "print(\"Validation Accuracy:\", accuracy_val_svm)\n",
        "\n",
        "# Predict labels for the training set\n",
        "y_pred_train_svm = best_svm_model.predict(X_resampled_svm)\n",
        "accuracy_train_svm = accuracy_score(y_resampled_svm, y_pred_train_svm)\n",
        "print(\"Training Accuracy:\", accuracy_train_svm)'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwiK84vfIiAY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, SpatialDropout1D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Split the upsampled data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the maximum sequence length\n",
        "max_len = X_train.shape[1]  # Assuming X_train is a matrix of shape (num_samples, max_features)\n",
        "\n",
        "# Convert string labels to numerical format\n",
        "y_train = y_train.map({'OFF': 1, 'NOT': 0})\n",
        "y_test = y_test.map({'OFF': 1, 'NOT': 0})\n",
        "\n",
        "# Define the RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_len))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "print(model.summary())\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train.values, y_train.values, epochs=5, batch_size=64, validation_data=(X_test, y_test), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyJVQuahKmKe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Flatten\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO8kRSK3Kq04"
      },
      "outputs": [],
      "source": [
        "# Convert TF-IDF matrix to array\n",
        "X_features = tfidf_matrix.toarray()\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y_downsampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the data for CNN input (3D tensor required)\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsHYjN0iKqoY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNEEFA4Kbgf_"
      },
      "source": [
        "TESTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5LO-Nl0TkPi"
      },
      "outputs": [],
      "source": [
        "#Read tweets from test sets\n",
        "test_tweet_a=pd.read_csv(\"/content/drive/MyDrive/testset-levela.tsv\", delimiter='\\t', encoding='utf-8')\n",
        "\n",
        "#Read tweet labels\n",
        "test_label_a=pd.read_csv('/content/drive/MyDrive/labels-levela.csv', names=['id', 'class_a'])\n",
        "\n",
        "#Merge tweets with labels by id\n",
        "test_tweet_a = test_tweet_a.merge(test_label_a, on='id')\n",
        "\n",
        "print(test_tweet_a.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIlXZlAvcd8G"
      },
      "outputs": [],
      "source": [
        "# Clean the tweets in the testing dataset\n",
        "clean_tweets(test_tweet_a)\n",
        "\n",
        "# Tokenize the cleaned tweets\n",
        "tokenized_test_tweets = tokenize_tweets(test_tweet_a['tweet'])\n",
        "\n",
        "# Lemmatize the tokenized tweets (if needed)\n",
        "lemmatized_test_tweets = lemmatize_tweets(tokenized_test_tweets)\n",
        "\n",
        "# Convert the lemmatized tweets back to strings\n",
        "lemmatized_test_tweet_strings = [' '.join(tokens) for tokens in lemmatized_test_tweets]\n",
        "\n",
        "# Vectorize the lemmatized tweet strings using TF-IDF\n",
        "test_tfidf_matrix, _ = tfidf_vectorize_tweets(lemmatized_test_tweet_strings)\n",
        "\n",
        "# Predict labels for the testing set\n",
        "y_pred_test = random_forest_model.predict(test_tfidf_matrix)\n",
        "\n",
        "# Print the predicted labels\n",
        "print(\"Predicted Labels:\", y_pred_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gcEl0qBdRpS"
      },
      "outputs": [],
      "source": [
        "y_true_test = test_tweet_a['class_a']\n",
        "accuracy_test = accuracy_score(y_true_test, y_pred_test)\n",
        "print(\"Test Accuracy:\", accuracy_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezzyqhVlt2wq"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWwpitr8EG6R",
        "outputId": "5bab77b8-2770-48da-e7a8-107799250aed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RckN51wYEIJU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}